{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab23162e-dc71-4300-ba4d-fb22db8a42d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from scipy.io import loadmat,savemat\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from dbpn import BasicNet as BDBPN\n",
    "import numpy as np\n",
    "from dataset import *\n",
    "from data import get_eval_set\n",
    "from functools import reduce\n",
    "\n",
    "#from scipy.misc import save\n",
    "import scipy.io as sio\n",
    "import time\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1726d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of GPUs\n",
    "gpus=1\n",
    "# Whether to use GPU (=True) or not (=False)\n",
    "gpu_mode=True\n",
    "#random seed to use. Default=123\n",
    "seed=123\n",
    "# Super-resolution upscale factor\n",
    "upscale_factor=2\n",
    "# Parent dirctory where test data is stored\n",
    "input_dir='Input'\n",
    "# Actual test dataset directory\n",
    "test_dataset='CCPs'\n",
    "# Number of threads for data loader to use\n",
    "threads=1\n",
    "# Testing batch size\n",
    "testBatchSize=1\n",
    "# Type of the trained model to use\n",
    "model_type='BDBPN' # BDBPN\n",
    "# SR pretrained base model\n",
    "# DBPNCCP2x_epoch_65.pth\n",
    "model_name='models/Pretrained/DBPNCCP2x_epoch_65.pth' # Inference model for all CCPs\n",
    "# Base location to save results\n",
    "output='Results/'\n",
    "# parser.add_argument('--chop_forward', type=bool, default=False)\n",
    "chop_forward=False\n",
    "# parser.add_argument('--self_ensemble', type=bool, default=False)\n",
    "self_ensemble=False\n",
    "# parser.add_argument('--residual', type=bool, default=False)\n",
    "residual=False\n",
    "# Fluorescence Level\n",
    "fluores_level= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab56a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus_list=range(gpus)\n",
    "#print(opt)\n",
    "\n",
    "cuda = gpu_mode\n",
    "if cuda and not torch.cuda.is_available():\n",
    "    raise Exception(\"No GPU found, please run without --cuda\")\n",
    "\n",
    "# help='random seed to use. Default=123'; opt.seed=123\n",
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    #torch.cuda.manual_seed(opt.seed)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f453899",
   "metadata": {},
   "source": [
    "### Loading the Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d754c681",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('===> Loading datasets')\n",
    "root='BioSR/Testing/CCPs/test_wf/'\n",
    "data_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Create the dataset\n",
    "# test_set = get_eval_set(os.path.join(opt.input_dir,opt.test_dataset), opt.upscale_factor)\n",
    "test_set = ImagePairTestDataset(root,upscale_factor=2, flevel=fluores_level,norm_flag=1)\n",
    "\n",
    "# Create the DataLoader\n",
    "test_data_loader = DataLoader(test_set, testBatchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd23dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('===> Building model')\n",
    "\n",
    "\n",
    "if model_type == 'BDBPN':\n",
    "    model = BDBPN(num_channels=1, base_filter=64,  feat = 256, num_stages=7, scale_factor=upscale_factor) ###D-DBPN\n",
    "    \n",
    "if cuda:\n",
    "    model = torch.nn.DataParallel(model, device_ids=gpus_list)\n",
    "\n",
    "chk= torch.load(model_name, map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(chk['model_state_dict'],strict=False)\n",
    "#optimizer.load_state_dict(chk['optimizer_state_dict'])\n",
    "#model.load_state_dict(torch.load(model_name, map_location=lambda storage, loc: storage))\n",
    "print('Pre-trained SR model is loaded.')\n",
    "\n",
    "if cuda:\n",
    "    model = model.cuda(gpus_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db76895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import cv2\n",
    "def save_img(img, img_name):\n",
    "    #save_img = img.squeeze().clamp(0, 1).numpy().transpose(1,2,0)\n",
    "    save_img = img.squeeze().numpy()\n",
    "    #save_img = img.squeeze().clamp(0,1).numpy()\n",
    "    # save img\n",
    "    save_dir=os.path.join(output,test_dataset+\"/level_0{}\".format(fluores_level))\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    #name,ext=os.path.splitext(img_name) # extra code to store as .mat file\n",
    "    save_fn = save_dir +'/'+ img_name # code to store as img file\n",
    "    #save_fn = save_dir +'/'+ name+'.mat'  # Code to store as .mat file\n",
    "    print(save_fn)\n",
    "    #result = Image.fromarray((save_img * 255).astype(np.uint8))\n",
    "    #result.save(save_dir +'/'+ img_name)\n",
    "    #savemat(save_dir+'/'+img_name+'.mat',{img_name: save_img})\n",
    "    #cv2.imwrite(save_fn, cv2.cvtColor(save_img*255, cv2.COLOR_BGR2RGB),  [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "    #cv2.imwrite(save_fn, cv2.cvtColor(save_img, cv2.COLOR_BGR2GRAY))\n",
    "    #tifffile.imwrite(save_fn,np.uint16(save_img*65535)) # code to store as img file\n",
    "    tifffile.imwrite(save_fn,np.uint8(save_img*300)) # Inference model for all CCPs, # code to store as img file\n",
    "    \n",
    "    #savemat(save_fn,{'prop':save_img}) # # Code to store as .mat file\n",
    "    #tifffile.imwrite(save_fn,save_img*65535)\n",
    "    #tifffile.imwrite(save_fn,save_img)\n",
    "    #cv2.imwrite(save_fn,save_img)\n",
    "    #cv2.imwrite(save_fn, cv2.cvtColor(save_img*255, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9044803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval():\n",
    "    model.eval()\n",
    "    for batch in test_data_loader:\n",
    "        with torch.no_grad():\n",
    "            input, bicubic, name = Variable(batch[0]), Variable(batch[1]), batch[2]\n",
    "        if cuda:\n",
    "            input = input.cuda(gpus_list[0])\n",
    "            bicubic = bicubic.cuda(gpus_list[0])\n",
    "\n",
    "        t0 = time.time()\n",
    "        if chop_forward:\n",
    "            with torch.no_grad():\n",
    "                prediction = chop_forward(input, model, upscale_factor)\n",
    "        else:\n",
    "            if self_ensemble:\n",
    "                with torch.no_grad():\n",
    "                    prediction = x8_forward(input, model)\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    #prediction = model(input.unsqueeze(1))\n",
    "                    prediction = model(input)\n",
    "                    #prediction = percentile_normalize(model(input))\n",
    "                    \n",
    "                \n",
    "        if residual:\n",
    "            prediction = prediction + bicubic\n",
    "\n",
    "        t1 = time.time()\n",
    "        print(\"===> Processing: %s || Timer: %.4f sec.\" % (name[0], (t1 - t0)))\n",
    "        save_img(prediction.cpu().data, name[0])\n",
    "        #save_img(prediction, name[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798e2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval Start!\n",
    "eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
